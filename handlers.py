import logging
import time
import asyncio
from typing import Optional, Dict, Any
from telegram import Update
from telegram.ext import ContextTypes

from config import Config
from services.openai_service import OpenAIService
from services.lightrag_service import LightRAGService
from services.moderation_service import add_to_moderation_queue
from services.message_filter import get_message_filter
from services.qa_logger import log_qa_interaction
from utils.text_utils import strip_markdown

logger = logging.getLogger(__name__)

class PriorityMessageQueue:
    """Smart priority queue for message processing with user-based prioritization."""

    def __init__(self, max_workers=3):
        self.queue = asyncio.PriorityQueue()
        self.user_last_processed = {}  # ĞšĞ¾Ğ³Ğ´Ğ° Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¹ Ñ€Ğ°Ğ· Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸ user_id
        self.workers = []
        self.max_workers = max_workers
        self.is_running = False
        self.handler_instance = None  # Reference to MessageHandlers instance

    def set_handler(self, handler):
        """Set reference to MessageHandlers instance for message processing."""
        self.handler_instance = handler

    async def add_message(self, message_data: Dict[str, Any], user_id: int):
        """Add message to priority queue with intelligent prioritization."""
        current_time = time.time()

        # Ğ Ğ°ÑÑÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚ (Ñ‡ĞµĞ¼ Ğ¼ĞµĞ½ÑŒÑˆĞµ Ñ‡Ğ¸ÑĞ»Ğ¾, Ñ‚ĞµĞ¼ Ğ²Ñ‹ÑˆĞµ Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚)
        if user_id not in self.user_last_processed:
            priority = 0  # ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ - Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ğ¹ Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚
            logger.debug(f"ğŸ” New user {user_id} - priority 0")
        else:
            # Ğ§ĞµĞ¼ Ğ´Ğ¾Ğ»ÑŒÑˆĞµ Ğ½Ğµ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°Ğ»Ğ¸ - Ñ‚ĞµĞ¼ Ğ²Ñ‹ÑˆĞµ Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚
            time_since_last = current_time - self.user_last_processed[user_id]
            if time_since_last > 300:  # Ğ‘Ğ¾Ğ»ÑŒÑˆĞµ 5 Ğ¼Ğ¸Ğ½ÑƒÑ‚ Ğ½Ğ°Ğ·Ğ°Ğ´
                priority = 1
                logger.debug(f"â° User {user_id} last seen {time_since_last:.0f}s ago - priority 1")
            elif time_since_last > 60:  # Ğ‘Ğ¾Ğ»ÑŒÑˆĞµ Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñ‹ Ğ½Ğ°Ğ·Ğ°Ğ´
                priority = 2
                logger.debug(f"â° User {user_id} last seen {time_since_last:.0f}s ago - priority 2")
            else:
                priority = 3  # ĞĞµĞ´Ğ°Ğ²Ğ½Ğ¾ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°Ğ»Ğ¸ - Ğ½Ğ¸Ğ·ĞºĞ¸Ğ¹ Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚
                logger.debug(f"â° User {user_id} processed recently - priority 3")

        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ timestamp ĞºĞ°Ğº tie-breaker Ğ´Ğ»Ñ Ğ¾Ğ´Ğ¸Ğ½Ğ°ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚Ğ¾Ğ²
        await self.queue.put((priority, current_time, message_data))
        queue_size = self.queue.qsize()

        logger.info(f"ğŸ“¥ Message queued: priority={priority}, user={user_id}, queue_size={queue_size}")

    async def process_messages(self):
        """Main worker loop for processing messages from the queue."""
        worker_id = len(self.workers)
        logger.info(f"ğŸƒâ€â™‚ï¸ Worker {worker_id} started")

        while self.is_running:
            try:
                # Get message from queue with timeout to allow clean shutdown
                try:
                    priority, timestamp, message_data = await asyncio.wait_for(
                        self.queue.get(), timeout=1.0
                    )
                except asyncio.TimeoutError:
                    continue  # Check if still running

                user_id = message_data['user_id']
                queue_size = self.queue.qsize()

                logger.info(f"âš¡ Worker {worker_id} processing: priority={priority}, user={user_id}, remaining={queue_size}")

                # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ²Ñ€ĞµĞ¼Ñ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸
                self.user_last_processed[user_id] = time.time()

                # ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ñ‡ĞµÑ€ĞµĞ· handler instance
                if self.handler_instance:
                    await self.process_single_message(message_data)
                else:
                    logger.error("âŒ No handler instance set for queue processing")

                # Mark task as done
                self.queue.task_done()

            except Exception as e:
                logger.error(f"âŒ Worker {worker_id} error: {e}")
                # Continue processing other messages

        logger.info(f"â¹ï¸ Worker {worker_id} stopped")

    async def process_single_message(self, message_data: Dict[str, Any]):
        """Process a single message using the handler instance."""
        try:
            update = message_data['update']
            context = message_data['context']

            # Call the original message processing logic
            await self.handler_instance._process_message_internal(update, context)

        except Exception as e:
            logger.error(f"âŒ Error processing queued message: {e}")

    async def start_workers(self):
        """Start worker tasks for processing the queue."""
        if self.is_running:
            logger.warning("âš ï¸ Workers already running")
            return

        self.is_running = True
        self.workers = []

        for i in range(self.max_workers):
            worker = asyncio.create_task(self.process_messages())
            self.workers.append(worker)

        logger.info(f"ğŸš€ Started {self.max_workers} queue workers")

    async def stop_workers(self):
        """Stop all worker tasks gracefully."""
        if not self.is_running:
            return

        logger.info("â¹ï¸ Stopping queue workers...")
        self.is_running = False

        # Wait for workers to finish
        if self.workers:
            await asyncio.gather(*self.workers, return_exceptions=True)

        self.workers = []
        logger.info("âœ… All queue workers stopped")

    def get_stats(self) -> Dict[str, Any]:
        """Get queue statistics."""
        return {
            'queue_size': self.queue.qsize(),
            'active_workers': len(self.workers),
            'is_running': self.is_running,
            'total_users_processed': len(self.user_last_processed),
            'max_workers': self.max_workers
        }

class MessageHandlers:
    """Message handlers for the Telegram bot."""

    def __init__(self, main_bot=None, queue_workers=3, auto_start_queue=True):
        """Initialize message handlers with OpenAI and LightRAG services."""
        self.openai_service = OpenAIService()
        self.lightrag_service = LightRAGService()
        self.message_filter = get_message_filter()
        self.main_bot = main_bot  # Reference to main bot for storing message references

        # Initialize priority queue for smart message processing
        self.priority_queue = PriorityMessageQueue(max_workers=queue_workers)
        self.priority_queue.set_handler(self)
        self.auto_start_queue = auto_start_queue

        logger.info(f"ğŸ“‹ Message handlers initialized with {queue_workers} queue workers")

    async def initialize(self):
        """Initialize async components (call this after creating the handler)."""
        if self.auto_start_queue:
            await self.start_queue()

    def send_to_moderation_queue(self, response: str, user_info: dict, original_message: str,
                                original_message_id: Optional[int] = None) -> str:
        """
        Send AI response to moderation queue instead of directly to user.

        Args:
            response: AI-generated response
            user_info: Dictionary containing user context (chat_id, user_id, username)
            original_message: Original user message text
            original_message_id: Telegram message ID to reply to (for group chats)

        Returns:
            Message ID for tracking in moderation queue
        """
        try:
            # Extract user context
            chat_id = user_info.get('chat_id')
            user_id = user_info.get('user_id')
            username = user_info.get('username')

            # Send to moderation queue
            message_id = add_to_moderation_queue(
                chat_id=chat_id,
                user_id=user_id,
                username=username,
                original_message=original_message,
                ai_response=response,
                original_message_id=original_message_id
            )

            logger.info(f"ğŸ“¤ Response sent to moderation queue:")
            logger.info(f"   ğŸ†” Moderation ID: {message_id}")
            logger.info(f"   ğŸ‘¤ User: {username} ({user_id})")
            logger.info(f"   ğŸ’¬ Chat: {chat_id}")
            logger.info(f"   ğŸ“„ Response length: {len(response)} chars")

            return message_id

        except Exception as e:
            logger.error(f"âŒ Failed to send response to moderation: {e}")
            raise

    async def handle_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """
        Handle incoming messages by adding them to the priority queue for processing.

        COMPREHENSIVE DIAGNOSTIC LOGGING ADDED to capture ALL message reception.

        Args:
            update: Telegram update object
            context: Telegram context object
        """
        # ==========================================
        # CRITICAL DIAGNOSTIC LOGGING - CAPTURES ALL MESSAGES BOT RECEIVES
        # ==========================================

        logger.info("ğŸ”¥ğŸ”¥ğŸ”¥ ========== MESSAGE RECEPTION DIAGNOSTIC ========== ğŸ”¥ğŸ”¥ğŸ”¥")

        # Log EVERY update that reaches this handler
        if update:
            logger.info(f"ğŸ“¨ UPDATE RECEIVED: update_id={getattr(update, 'update_id', 'UNKNOWN')}")

            if update.message:
                user = update.message.from_user
                chat = update.message.chat

                logger.info(f"ğŸ‘¤ USER INFO:")
                logger.info(f"   ğŸ“‹ User ID: {user.id}")
                logger.info(f"   ğŸ“› Username: {user.username}")
                logger.info(f"   ğŸ“ First Name: {user.first_name}")
                logger.info(f"   ğŸ“ Last Name: {user.last_name}")
                logger.info(f"   ğŸ¤– Is Bot: {user.is_bot}")

                logger.info(f"ğŸ’¬ CHAT INFO:")
                logger.info(f"   ğŸ“‹ Chat ID: {chat.id}")
                logger.info(f"   ğŸ·ï¸ Chat Type: {chat.type}")
                logger.info(f"   ğŸ“› Chat Title: {getattr(chat, 'title', 'N/A')}")

                logger.info(f"ğŸ“„ MESSAGE INFO:")
                logger.info(f"   ğŸ“‹ Message ID: {update.message.message_id}")
                logger.info(f"   ğŸ“ Text: '{update.message.text}'")
                logger.info(f"   ğŸ“ Text Length: {len(update.message.text) if update.message.text else 0}")
                logger.info(f"   ğŸ“… Date: {update.message.date}")

                # Check admin status for this user
                is_admin = Config.is_admin(user.id)
                logger.info(f"ğŸ”‘ ADMIN STATUS: {is_admin}")
                logger.info(f"ğŸ”‘ ADMIN LIST: {Config.ADMIN_CHAT_IDS}")

            else:
                logger.info("âŒ UPDATE HAS NO MESSAGE OBJECT")
        else:
            logger.info("âŒ NO UPDATE OBJECT RECEIVED")

        logger.info("ğŸ”¥ğŸ”¥ğŸ”¥ ================================================== ğŸ”¥ğŸ”¥ğŸ”¥")

        # Original filtering logic continues here...
        if not update.message or not update.message.text:
            logger.info("âŒ EARLY EXIT: No message or no text")
            return

        # Basic chat type filtering before queueing
        if update.message.chat.type == 'private':
            logger.info("âŒ EARLY EXIT: Private message ignored")
            return  # Ğ˜Ğ³Ğ½Ğ¾Ñ€Ğ¸Ñ€ÑƒĞµĞ¼ Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ

        if update.message.chat.type not in ['group', 'supergroup']:
            logger.info(f"âŒ EARLY EXIT: Unsupported chat type: {update.message.chat.type}")
            return  # Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ² Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ°Ñ…

        user_id = update.message.from_user.id

        # Ignore messages from admins to prevent processing admin replies as questions
        if Config.is_admin(user_id):
            logger.info(f"â›” ADMIN MESSAGE IGNORED: Admin {user_id} message skipped in group chat")
            return

        message_data = {
            'update': update,
            'context': context,
            'user_id': user_id,
            'message_text': update.message.text.strip(),
            'timestamp': time.time()
        }

        logger.info(f"âœ… MESSAGE PASSED INITIAL FILTERING - Adding to queue for user {user_id}")

        # Add to priority queue for processing
        await self.priority_queue.add_message(message_data, user_id)

    async def _process_message_internal(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """
        Internal message processing logic - called by queue workers:
        1. Length check (< 10 chars â†’ ignore)
        2. Relevance check (filter â†’ ignore if irrelevant)
        3. Process through RAG â†’ send to moderation silently

        Args:
            update: Telegram update object
            context: Telegram context object
        """
        if not update.message or not update.message.text:
            return

        message_text = update.message.text.strip()

        logger.info(f"ğŸ“¥ ĞŸĞĞ›Ğ£Ğ§Ğ•Ğ Ğ’ĞĞŸĞ ĞĞ¡: '{message_text[:100]}{'...' if len(message_text) > 100 else ''}', Ğ´Ğ»Ğ¸Ğ½Ğ°: {len(message_text)}, Ğ¾Ñ‚ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ: {update.message.from_user.id}")

        # Step 1: Length check - ignore short messages
        if len(message_text) < 10:
            logger.info(f"âŒ ĞĞ¢ĞšĞ›ĞĞĞ•ĞĞ ĞŸĞ Ğ”Ğ›Ğ˜ĞĞ•: ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ: '{message_text}', Ğ´Ğ»Ğ¸Ğ½Ğ°: {len(message_text)}, Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ: Ğ½Ğµ_Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞ»Ğ¾ÑÑŒ (ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼_ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹)")
            return

        # Step 2: Basic relevance check using filter
        try:
            should_process = await self.message_filter.should_process(
                message_text,
                update.message.from_user.id,
                update.effective_chat.id
            )
        except Exception as e:
            logger.error(f"âŒ Error in message filtering: {e}")
            # Default to not processing on filter error
            should_process = False

        if not should_process:
            logger.info(f"âŒ ĞĞ¢ĞšĞ›ĞĞĞ•ĞĞ ĞŸĞ Ğ Ğ•Ğ›Ğ•Ğ’ĞĞĞ¢ĞĞĞ¡Ğ¢Ğ˜: ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ: '{message_text[:100]}...', Ğ´Ğ»Ğ¸Ğ½Ğ°: {len(message_text)}, Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ: ĞĞ•Ğ¢")
            return

        # Log successful processing start
        logger.info(f"âœ… ĞŸĞ Ğ˜ĞĞ¯Ğ¢Ğ Ğš ĞĞ‘Ğ ĞĞ‘ĞĞ¢ĞšĞ•: ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ: '{message_text[:100]}...', Ğ´Ğ»Ğ¸Ğ½Ğ°: {len(message_text)}, Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ğ¾ÑÑ‚ÑŒ: Ğ”Ğ")

        # Step 3: Process relevant message through RAG pipeline
        logger.info("âœ… Message relevant - processing through RAG pipeline")

        # Store original message reference for later reply
        if self.main_bot:
            self.main_bot.store_original_message_reference(
                chat_id=update.effective_chat.id,
                user_id=update.message.from_user.id,
                message_id=update.message.message_id
            )

        try:
            processing_start_time = time.time()

            logger.info("="*80)
            logger.info("ğŸ” STARTING REQUEST PROCESSING")
            logger.info(f"ğŸ“ Original user query: '{message_text}'")
            logger.info("="*80)

            # Search for relevant information in LightRAG
            logger.info("ğŸ” STEP 1: Searching LightRAG...")
            rag_context = await self.lightrag_service.query(message_text)

            if rag_context and rag_context.strip():
                logger.info(f"âœ… LightRAG Response Found:")
                logger.info(f"ğŸ“Š Length: {len(rag_context)} chars")
                logger.info(f"ğŸ“„ First 500 chars: {rag_context[:500]}{'...' if len(rag_context) > 500 else ''}")
                context_message = f"Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ: {message_text}\n\nĞ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ· Ğ±Ğ°Ğ·Ñ‹ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹:\n{rag_context}"
            else:
                logger.warning("âŒ No relevant information found in LightRAG")
                context_message = f"Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ: {message_text}\n\nĞ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ· Ğ±Ğ°Ğ·Ñ‹ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹: null"

            # Send combined query to OpenAI Assistant
            logger.info("ğŸ” STEP 2: Sending to OpenAI Assistant...")
            assistant_response = await self.openai_service.process_query(context_message)

            if not assistant_response:
                logger.error("âŒ No response from OpenAI Assistant")
                return

            logger.info(f"âœ… OpenAI Assistant Response:")
            logger.info(f"ğŸ“Š Response length: {len(assistant_response)} chars")

            # Strip markdown formatting before moderation
            clean_response = strip_markdown(assistant_response)

            # Prepare user context for moderation
            user_info = {
                'chat_id': update.effective_chat.id,
                'user_id': update.message.from_user.id,
                'username': update.message.from_user.username or update.message.from_user.first_name
            }

            # Log successful QA interaction (only if valid context was found)
            if rag_context and rag_context.strip() and "null" not in context_message.lower():
                try:
                    processing_duration = int((time.time() - processing_start_time) * 1000)
                    log_qa_interaction(
                        question=message_text,
                        answer=clean_response,
                        context=rag_context,
                        user_info=user_info,
                        processing_time_ms=processing_duration,
                        original_message_length=len(message_text),
                        cleaned_response_length=len(clean_response),
                        lightrag_context_length=len(rag_context)
                    )
                    logger.info(f"ğŸ“ QA interaction logged successfully (duration: {processing_duration}ms)")
                except Exception as qa_log_error:
                    logger.error(f"âŒ Failed to log QA interaction: {qa_log_error}")

            # Send to moderation queue silently (no user notification)
            try:
                moderation_id = self.send_to_moderation_queue(
                    response=clean_response,
                    user_info=user_info,
                    original_message=message_text,
                    original_message_id=update.message.message_id
                )
                logger.info(f"ğŸ”„ RESPONSE SENT TO MODERATION (ID: {moderation_id})")
                logger.info("="*80)
            except Exception as moderation_error:
                logger.error(f"âŒ Moderation failed: {moderation_error}")

        except Exception as e:
            logger.error(f"âŒ Error processing request: {e}")
            # No error message to user - just log the error

    @staticmethod
    async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
        """
        Handle the /start command.

        Args:
            update: Telegram update object
            context: Telegram context object
        """
        welcome_message = (
            "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! Ğ¯ Ğ±Ğ¾Ñ‚-ĞºÑƒÑ€Ğ°Ñ‚Ğ¾Ñ€ Ğ•ĞºĞ°Ñ‚ĞµÑ€Ğ¸Ğ½Ğ°.\n"
            "ĞŸÑ€Ğ¾ÑÑ‚Ğ¾ Ğ·Ğ°Ğ´Ğ°Ğ²Ğ°Ğ¹Ñ‚Ğµ Ğ¼Ğ½Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‡Ğ¸Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ - Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ÑÑ, "
            "ĞºĞ°ĞºĞ¸Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ¾Ñ‚Ğ½Ğ¾ÑÑÑ‚ÑÑ Ğº Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ¸ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸!"
        )

        try:
            await update.message.reply_text(welcome_message)
            logger.info(f"Start command handled for user {update.message.from_user.id}")
        except Exception as e:
            logger.error(f"Error handling start command: {e}")

    @staticmethod
    async def error_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
        """
        Handle errors that occur during bot operation.

        Args:
            update: Telegram update object
            context: Telegram context object
        """
        logger.error(f"Update {update} caused error {context.error}")

        # Don't send error messages to users for now
        # In production, you might want to send a generic error message

    async def start_queue(self):
        """Start the priority queue workers."""
        await self.priority_queue.start_workers()
        logger.info("ğŸš€ Message processing queue started")

    async def stop_queue(self):
        """Stop the priority queue workers gracefully."""
        await self.priority_queue.stop_workers()
        logger.info("â¹ï¸ Message processing queue stopped")

    def get_queue_stats(self) -> Dict[str, Any]:
        """Get statistics about the message processing queue."""
        return self.priority_queue.get_stats()